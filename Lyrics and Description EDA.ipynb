{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADS 509\n",
    "#### Assignment 2\n",
    "#### Abby Tan\n",
    "#### GitHub Link: https://github.com/Abby-Tan/ADS509_Assignment_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.1.0.tar.gz (216 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-2.1.0-py3-none-any.whl size=212377 sha256=c23006e865529c5f34c8f2230232f2e35ab4ce8e42cb77fb2f29dd4f486a9450\n",
      "  Stored in directory: c:\\users\\abby0\\appdata\\local\\pip\\cache\\wheels\\ae\\80\\43\\3b56e58669d65ea9ebf38b9574074ca248143b61f45e114a6b\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lexical-diversity\n",
      "  Downloading lexical_diversity-0.1.1-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: lexical-diversity\n",
      "Successfully installed lexical-diversity-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lexical-diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abby0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import string\n",
    "from lexical_diversity import lex_div as ld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"C:/Users/abby0/OneDrive/Desktop/MSADS/ADS-509 Applied Text Mining/Module 2/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = 13\n",
    "    num_unique_tokens = 9\n",
    "    lexical_diversity = 0.69\n",
    "    num_characters = 55\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.690 in the data.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: The assertion statements are beneficial for debugging. It will raise errors if the condition from the assertion statement is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the lyrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = []\n",
    "songs = []\n",
    "lyrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in artist_folders:\n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "    for f_name in artist_files:\n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile:\n",
    "            artists.append(artist)\n",
    "            songs.append(f_name)\n",
    "            lyrics.append(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = pd.DataFrame({'artists':artists,\n",
    "                          'songs'  :songs,\n",
    "                          'lyrics' :lyrics })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('joji_','')\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('postmalone_','')\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('.txt','')\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joji</td>\n",
       "      <td>amazonian pet</td>\n",
       "      <td>amazonian pet\\n\\nI'm an old man rich, amazonia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joji</td>\n",
       "      <td>attention</td>\n",
       "      <td>attention\\n\\nGirl, would it kill you just to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joji</td>\n",
       "      <td>bitter fuck</td>\n",
       "      <td>bitter fuck\\n\\nI find it hard to be myself\\nI ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists          songs                                             lyrics\n",
       "0    Joji  amazonian pet  amazonian pet\\n\\nI'm an old man rich, amazonia...\n",
       "1    Joji      attention  attention\\n\\nGirl, would it kill you just to t...\n",
       "2    Joji    bitter fuck  bitter fuck\\n\\nI find it hard to be myself\\nI ..."
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "PostMalone_df = pd.read_csv(data_location + twitter_folder + 'PostMalone_follower_data.txt', sep='\\t')\n",
    "PostMalone_df['artists'] = 'PostMalone'\n",
    "PostMalone_df = PostMalone_df[['artists','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "Joji_df = pd.read_csv(data_location + twitter_folder + 'sushitrash_follower_data.txt', sep='\\t')\n",
    "Joji_df['artists'] = 'Joji'\n",
    "Joji_df = Joji_df[['artists','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.concat([PostMalone_df, Joji_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>Hi People I'm Republican I Rap sing and do reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>hi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artists                                        description\n",
       "0  PostMalone  Hi People I'm Republican I Rap sing and do reg...\n",
       "1  PostMalone                                                hi!\n",
       "2  PostMalone                                                NaN"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    return text\n",
    "\n",
    "# reference: https://stackoverflow.com/questions/39782418/remove-punctuations-in-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create your clean twitter data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "df_twitter['desc_2'] = df_twitter['description'].astype(str)\n",
    "df_twitter[\"desc_2\"] = df_twitter['desc_2'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on whitespace\n",
    "df_twitter['desc_2'] = df_twitter['desc_2'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "df_twitter = df_twitter.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "df_twitter['desc_2'] = df_twitter['desc_2'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))\n",
    "\n",
    "# reference: https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>postmalone</td>\n",
       "      <td>hi people i'm republican i rap sing and do reg...</td>\n",
       "      <td>hi people republican rap sing reggae music man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>postmalone</td>\n",
       "      <td>hi!</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>postmalone</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artists                                        description  \\\n",
       "0  postmalone  hi people i'm republican i rap sing and do reg...   \n",
       "1  postmalone                                                hi!   \n",
       "2  postmalone                                                nan   \n",
       "\n",
       "                                              desc_2  \n",
       "0  hi people republican rap sing reggae music man...  \n",
       "1                                                 hi  \n",
       "2                                                nan  "
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create your clean lyrics data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "df_lyrics['lyrics_2'] = df_lyrics['lyrics'].astype(str)\n",
    "df_lyrics['lyrics_2'] = df_lyrics['lyrics_2'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on whitespace\n",
    "df_lyrics['lyrics_2'] = df_lyrics['lyrics_2'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "df_lyrics = df_lyrics.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "df_lyrics['lyrics_2'] = df_lyrics['lyrics_2'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_len</th>\n",
       "      <th>lyrics_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joji</td>\n",
       "      <td>amazonian pet</td>\n",
       "      <td>amazonian pet\\n\\ni'm an old man rich, amazonia...</td>\n",
       "      <td>1</td>\n",
       "      <td>amazonian pet old man rich amazonian pet rap g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joji</td>\n",
       "      <td>attention</td>\n",
       "      <td>attention\\n\\ngirl, would it kill you just to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>attention girl would kill throw little bit att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joji</td>\n",
       "      <td>bitter fuck</td>\n",
       "      <td>bitter fuck\\n\\ni find it hard to be myself\\ni ...</td>\n",
       "      <td>1</td>\n",
       "      <td>bitter fuck find hard shed skin everybody else...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists          songs                                             lyrics  \\\n",
       "0    joji  amazonian pet  amazonian pet\\n\\ni'm an old man rich, amazonia...   \n",
       "1    joji      attention  attention\\n\\ngirl, would it kill you just to t...   \n",
       "2    joji    bitter fuck  bitter fuck\\n\\ni find it hard to be myself\\ni ...   \n",
       "\n",
       "  lyrics_len                                           lyrics_2  \n",
       "0          1  amazonian pet old man rich amazonian pet rap g...  \n",
       "1          1  attention girl would kill throw little bit att...  \n",
       "2          1  bitter fuck find hard shed skin everybody else...  "
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens_list, tokens_text, verbose=True):\n",
    "    \n",
    "    num_tokens = len(tokens_list)\n",
    "    num_unique_tokens = len(set(tokens_list))\n",
    "    num_characters = len(tokens_text)\n",
    "    lexical_diversity = ld.ttr(tokens_list)\n",
    "    most_common_5 = Counter(tokens_list).most_common(5)\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "    # print the five most common tokens    \n",
    "        print(f\"The five most common tokens are {most_common_5} in the data.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter description\n",
    "postmalone_desc = df_twitter[df_twitter['artists'] == 'postmalone'][['desc_2']]\n",
    "postmalone_desc_text = re.sub('\\s+\\.','.', ' '.join(postmalone_desc['desc_2']))\n",
    "postmalone_desc_list = postmalone_desc_text.split()\n",
    "\n",
    "joji_desc = df_twitter[df_twitter['artists'] == 'joji'][['desc_2']]\n",
    "joji_desc_text = re.sub('\\s+\\.','.', ' '.join(joji_desc['desc_2']))\n",
    "joji_desc_list = joji_desc_text.split()\n",
    "\n",
    "# song lyrics\n",
    "postmalone_lyrics = df_lyrics[df_lyrics['artists'] == 'postmalone'][['lyrics_2']]\n",
    "postmalone_lyrics_text = re.sub('\\s+\\.','.', ' '.join(postmalone_lyrics['lyrics_2']))\n",
    "postmalone_lyrics_list = postmalone_lyrics_text.split()\n",
    "\n",
    "joji_lyrics = df_lyrics[df_lyrics['artists'] == 'joji'][['lyrics_2']]\n",
    "joji_lyrics_text = re.sub('\\s+\\.','.', ' '.join(joji_lyrics['lyrics_2']))\n",
    "joji_lyrics_list = joji_lyrics_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics for Post Malone follower description:\n",
      "There are 340606 tokens in the data.\n",
      "There are 77541 unique tokens in the data.\n",
      "There are 1975435 characters in the data.\n",
      "The lexical diversity is 0.228 in the data.\n",
      "The five most common tokens are [('nan', 33505), ('co', 2029), ('de', 1956), ('https', 1911), ('•', 1909)] in the data.\n",
      "\n",
      "Descriptive statistics for Joji follower description:\n",
      "There are 425390 tokens in the data.\n",
      "There are 81009 unique tokens in the data.\n",
      "There are 2718991 characters in the data.\n",
      "The lexical diversity is 0.190 in the data.\n",
      "The five most common tokens are [('nan', 54672), ('music', 3922), ('co', 3447), ('love', 3008), ('och', 2275)] in the data.\n",
      "\n",
      "Descriptive statistics for Post Malone lyrics:\n",
      "There are 4277 tokens in the data.\n",
      "There are 1066 unique tokens in the data.\n",
      "There are 24264 characters in the data.\n",
      "The lexical diversity is 0.249 in the data.\n",
      "The five most common tokens are [('yeah', 140), ('know', 86), ('like', 85), ('got', 72), ('wanna', 69)] in the data.\n",
      "\n",
      "Descriptive statistics for Joji lyrics:\n",
      "There are 1646 tokens in the data.\n",
      "There are 464 unique tokens in the data.\n",
      "There are 9393 characters in the data.\n",
      "The lexical diversity is 0.282 in the data.\n",
      "The five most common tokens are [('yeah', 62), ('know', 49), ('fun', 39), ('fuck', 34), ('right', 34)] in the data.\n"
     ]
    }
   ],
   "source": [
    "print('Descriptive statistics for Post Malone follower description:')\n",
    "descriptive_stats(postmalone_desc_list, postmalone_desc_text, verbose=True)\n",
    "print('\\nDescriptive statistics for Joji follower description:')\n",
    "descriptive_stats(joji_desc_list, joji_desc_text, verbose=True)\n",
    "print('\\nDescriptive statistics for Post Malone lyrics:')\n",
    "descriptive_stats(postmalone_lyrics_list, postmalone_lyrics_text, verbose=True)\n",
    "print('\\nDescriptive statistics for Joji lyrics:')\n",
    "descriptive_stats(joji_lyrics_list, joji_lyrics_text, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: The top five words will most likely be the stopwords if we don't remove them.\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: My prior belief is the artists should have low lexical diversity, especially in their lyrics. My assumption is each of the artists have their personal style when writing songs and have preferences and favor vocabulary to use. By looking at the descriptive statistics, both of the two artists have low lexical diversity of 0.249 and 0.282. This conforms to my prior belifes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    # return(s in emoji.UNICODE_EMOJI['en'])\n",
    "    return(emoji.is_emoji(s))\n",
    "assert(is_emoji(\"❤️\"))\n",
    "assert(not is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emojis 😁\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten most common emojis for Post Malone are:\n",
      "[('✨', 327), ('🏳️\\u200d🌈', 294), ('❤️', 232), ('🖤', 208), ('🇲🇽', 172), ('🤍', 170), ('💜', 166), ('🔞', 126), ('🦋', 102), ('🇵🇭', 97)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "postmalone_emoji = []\n",
    "for text in postmalone_desc_list:\n",
    "    if is_emoji(text):\n",
    "        postmalone_emoji.append(text)\n",
    "\n",
    "print('Top ten most common emojis for Post Malone are:')\n",
    "print(Counter(postmalone_emoji).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten most common emojis for Joji are:\n",
      "[('♥', 356), ('❤️', 269), ('🏳️\\u200d🌈', 245), ('❤', 211), ('✨', 150), ('🌈', 89), ('✌', 49), ('✌️', 48), ('🎶', 42), ('📸', 38)]\n"
     ]
    }
   ],
   "source": [
    "joji_emoji = []\n",
    "for text in joji_desc_list:\n",
    "    if is_emoji(text):\n",
    "        joji_emoji.append(text)\n",
    "\n",
    "print('Top ten most common emojis for Joji are:')\n",
    "print(Counter(joji_emoji).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter description with punctuation\n",
    "postmalone_desc = df_twitter[df_twitter['artists'] == 'postmalone'][['description']]\n",
    "postmalone_desc_text = re.sub('\\s+\\.','.', ' '.join(postmalone_desc['description']))\n",
    "postmalone_desc_list = postmalone_desc_text.split()\n",
    "\n",
    "joji_desc = df_twitter[df_twitter['artists'] == 'joji'][['description']]\n",
    "joji_desc_text = re.sub('\\s+\\.','.', ' '.join(joji_desc['description']))\n",
    "joji_desc_list = joji_desc_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten most common hashtags for PostMalone are:\n",
      "[('#1', 122), ('#blacklivesmatter', 42), ('#blm', 38), ('#ez4ence', 17), ('#vtuber', 15), ('#bts', 14), ('#freepalestine', 12), ('#bitcoin', 12), ('#dubnation', 10), ('#stopasianhate', 9)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "postmalone_hashtag = []\n",
    "for text in postmalone_desc_list:\n",
    "    if re.findall(r\"#(\\w+)\", text):\n",
    "        postmalone_hashtag.append(text)\n",
    "        \n",
    "print('Top ten most common hashtags for PostMalone are:')\n",
    "print(Counter(postmalone_hashtag).most_common(10))\n",
    "\n",
    "# Reference: https://stackoverflow.com/questions/2527892/parsing-a-tweet-to-extract-hashtags-into-an-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten most common hashtags for PostMalone are:\n",
      "[('#blacklivesmatter', 78), ('#music', 72), ('#blm', 44), ('#1', 43), ('#edm', 36), ('#teamfollowback', 19), ('#art', 19), ('#dj', 15), ('#directioner', 15), ('#house', 14)]\n"
     ]
    }
   ],
   "source": [
    "joji_hashtag = []\n",
    "for text in joji_desc_list:\n",
    "    if re.findall(r\"#(\\w+)\", text):\n",
    "        joji_hashtag.append(text)\n",
    "        \n",
    "print('Top ten most common hashtags for PostMalone are:')\n",
    "print(Counter(joji_hashtag).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse the code from the top\n",
    "artists = []\n",
    "songs = []\n",
    "\n",
    "for artist in artist_folders:\n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "    for f_name in artist_files:\n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile:\n",
    "            artists.append(artist)\n",
    "            songs.append(infile.readline())\n",
    "            \n",
    "df_lyrics = pd.DataFrame({'artists':artists,\n",
    "                          'songs'  :songs })\n",
    "\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Malone\n",
    "postmalone_songs = df_lyrics[df_lyrics['artists'] == 'PostMalone'][['songs']]\n",
    "postmalone_songs_text = re.sub('\\s+\\.','.', ' '.join(postmalone_songs['songs']))\n",
    "postmalone_songs_list = postmalone_songs_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('god', 2), ('40', 1), ('funk', 1), ('big', 1), ('lie', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(postmalone_songs_list).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joji\n",
    "joji_songs = df_lyrics[df_lyrics['artists'] == 'Joji'][['songs']]\n",
    "joji_songs_text = re.sub('\\s+\\.','.', ' '.join(joji_songs['songs']))\n",
    "joji_songs_list = joji_songs_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('my', 2), ('i', 2), ('the', 2), ('in', 2), ('amazonian', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(joji_songs_list).most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: The reuglar expression of \\s+ will match on one or more whitespace. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your lyric length comparison chart here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>lyrics_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joji</td>\n",
       "      <td>amazonian pet old man rich amazonian pet rap g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joji</td>\n",
       "      <td>attention girl would kill throw little bit att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joji</td>\n",
       "      <td>bitter fuck find hard shed skin everybody else...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists                                           lyrics_2\n",
       "0    joji  amazonian pet old man rich amazonian pet rap g...\n",
       "1    joji  attention girl would kill throw little bit att...\n",
       "2    joji  bitter fuck find hard shed skin everybody else..."
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics = df_lyrics[['artists', 'lyrics_2']]\n",
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-787-a2c4469e6652>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lyrics['lyrics_len'] = df_lyrics['lyrics_2'].str.split(' ').str.len()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>lyrics_2</th>\n",
       "      <th>lyrics_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joji</td>\n",
       "      <td>amazonian pet old man rich amazonian pet rap g...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joji</td>\n",
       "      <td>attention girl would kill throw little bit att...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joji</td>\n",
       "      <td>bitter fuck find hard shed skin everybody else...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists                                           lyrics_2  lyrics_len\n",
       "0    joji  amazonian pet old man rich amazonian pet rap g...          94\n",
       "1    joji  attention girl would kill throw little bit att...          85\n",
       "2    joji  bitter fuck find hard shed skin everybody else...          73"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics['lyrics_len'] = df_lyrics['lyrics_2'].str.split(' ').str.len()\n",
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artists\n",
       "joji          AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "postmalone    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: lyrics_len, dtype: object"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_lyrics.groupby('artists')['lyrics_len'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
